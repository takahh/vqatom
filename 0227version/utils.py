import numpy as np
import torch
import logging
import pytz
import random
import os
import yaml
import shutil
from datetime import datetime
from ogb.nodeproppred import Evaluator
from dgl import function as fn

CPF_data = ["cora", "citeseer", "pubmed", "a-computer", "a-photo"]
OGB_data = ["ogbn-arxiv", "ogbn-products"]
NonHom_data = ["pokec", "penn94"]
BGNN_data = ["house_class", "vk_class"]
CORE_ELEMENTS = {"5", "6", "7", "8", "14", "15", "16"}

CBDICT = {
'1_0_0_0_0_0_1_0_0_0': 511,
'6_0_3_1_1_2_6_2_1_1': 422,
'6_0_3_1_1_2_6_2_2_1': 422,
'6_0_3_1_1_2_6_2_3_1': 371,
'1_0_0_0_0_0_0_0_0_0': 359,
'8_0_3_0_0_1_0_0_0_0': 348,
'6_0_3_1_1_3_6_2_1_0': 341,
'3_1_1_0_0_0_3_1_1_0': 322,
'6_0_4_0_0_1_0_0_0_0': 319,
'6_0_3_1_1_0_6_2_0_0': 317,
'6_0_4_0_0_2_0_0_0_0': 317,
'3_1_0_0_0_0_3_1_1_0': 311,
'6_0_3_1_1_3_6_2_2_0': 295,
'1_0_0_0_0_2_1_0_0_0': 248,
'6_0_3_1_1_2_6_2_4_1': 246,
'6_0_3_1_1_3_6_2_3_0': 238,
'6_0_3_1_1_0_6_3_0_0': 227,
'6_0_4_0_0_0_6_3_0_0': 221,
'6_0_3_0_0_3_0_0_0_0': 216,
'3_0_0_0_0_0_3_0_0_0': 211,
'6_0_4_0_1_2_6_0_2_0': 207,
'2_0_0_0_0_0_2_0_0_0': 206,
'6_0_4_0_0_2_0_1_0_0': 205,
'1_0_0_0_0_3_1_0_0_0': 194,
'6_0_4_0_1_2_6_0_1_0': 191,
'6_0_4_0_0_0_6_2_0_0': 190,
'6_0_4_0_1_2_6_0_3_0': 182,
'6_0_4_0_1_0_6_2_0_0': 180,
'9_0_4_0_0_1_0_0_0_0': 179,
'1_0_0_0_0_2_0_0_0_0': 178,
'8_0_3_0_0_2_0_1_0_0': 177,
'7_0_3_0_0_2_0_0_0_0': 177,
'4_1_2_0_0_0_4_0_1_0': 173,
'2_0_0_0_0_0_0_0_0_0': 171,
'8_0_3_0_0_0_6_3_0_0': 169,
'6_0_3_1_1_3_6_3_2_0': 164,
'6_0_3_0_0_3_0_1_0_0': 164,
'6_0_3_1_1_3_5_3_1_0': 163,
'3_0_0_0_0_0_3_1_1_0': 162,
'6_0_3_1_1_3_5_2_1_0': 162,
'6_0_4_0_0_0_8_2_0_0': 162,
'1_0_0_0_0_0_1_1_0_0': 161,
'6_0_3_1_1_3_6_3_1_0': 161,
'7_0_3_0_0_2_0_1_0_0': 160,
'4_0_2_0_0_0_4_0_0_0': 156,
'6_0_4_0_0_1_0_1_0_0': 156,
'6_0_3_1_1_3_5_3_2_0': 155,
'7_0_3_1_1_2_6_2_2_0': 151,
'17_0_4_0_0_1_0_1_0_0': 149,
'6_0_4_0_0_3_0_0_0_0': 148,
'7_0_3_1_1_2_6_2_1_0': 148,
'3_1_0_0_0_2_3_1_1_0': 147,
'3_1_1_0_0_2_3_1_1_0': 147,
'6_0_3_1_1_3_6_2_4_0': 146,
'6_0_3_1_1_2_6_2_0_1': 144,
'1_0_0_0_0_3_0_0_0_0': 140,
'9_0_4_0_0_1_0_1_0_0': 138,
'1_0_0_0_0_1_1_0_0_0': 137,
'6_0_3_1_1_0_7_2_0_0': 137,
'8_0_4_0_0_1_0_0_0_0': 136,
'4_0_0_0_0_0_4_0_0_0': 134,
'7_0_3_1_1_2_5_2_1_0': 133,
'8_0_3_0_0_1_0_1_0_0': 133,
'6_0_3_1_1_3_5_2_2_0': 131,
'3_1_0_0_0_0_3_0_0_0': 131,
'7_0_3_1_1_2_5_2_2_0': 131,
'3_1_0_0_0_0_4_0_0_0': 131,
'6_0_4_0_1_2_6_0_4_0': 123,
'6_0_3_1_1_3_6_3_3_0': 122,
'7_0_3_0_0_0_6_3_0_0': 122,
'3_1_0_0_0_3_3_1_1_0': 121,
'6_0_3_1_1_2_5_2_2_1': 121,
'6_0_4_0_0_0_7_3_0_0': 116,
'1_1_0_0_0_0_1_0_1_0': 116,
'1_0_0_0_0_0_2_0_0_0': 115,
'2_0_0_0_0_0_1_0_0_0': 113,
'4_0_1_0_0_0_4_0_0_0': 112,
'6_0_3_1_1_3_6_2_0_0': 112,
'6_0_3_1_1_0_8_1_0_0': 111,
'3_1_1_0_0_3_3_1_1_0': 111,
'6_0_3_1_1_2_5_2_1_1': 110,
'6_0_3_1_1_2_6_2_5_1': 110,
'6_0_4_0_1_3_6_0_1_0': 109,
'7_0_3_1_1_0_6_3_0_0': 108,
'3_0_0_0_0_0_4_0_0_0': 105,
'6_0_3_1_1_3_5_3_3_0': 104,
'3_0_0_0_0_2_3_0_0_0': 104,
'6_0_4_0_1_0_6_3_0_0': 103,
'4_1_1_0_0_0_4_0_1_0': 103,
'3_1_1_0_0_1_3_1_1_0': 103,
'3_0_0_0_0_0_0_0_0_0': 103,
'6_0_4_0_1_2_5_0_2_0': 103,
'6_0_4_0_0_2_6_3_0_0': 103,
'6_0_3_1_1_2_6_3_0_1': 102,
'4_0_0_0_0_0_3_1_1_0': 102,
'7_0_3_1_1_2_6_2_3_0': 102,
'6_0_3_1_1_3_5_2_3_0': 101,
'6_0_3_0_0_0_8_1_0_0': 101,
'6_0_4_0_1_2_5_0_1_0': 100,
'1_0_0_0_0_1_0_0_0_0': 100,
'7_0_3_1_1_2_5_2_3_0': 99,
'3_1_0_0_0_1_3_1_1_0': 99,
'2_0_0_0_0_2_2_0_0_0': 98,
'1_0_0_0_0_0_0_0_1_0': 98,
'6_0_3_1_1_2_5_2_3_1': 98,
'1_1_0_0_0_0_0_0_0_0': 96,
'1_0_0_1_0_0_0_0_0_0': 95,
'6_0_4_0_1_2_5_0_3_0': 94,
'7_0_3_1_1_0_6_2_0_0': 94,
'6_0_4_0_0_1_6_3_0_0': 93,
'6_0_4_0_1_3_6_0_2_0': 93,
'3_1_0_0_0_0_4_0_1_0': 91,
'6_0_4_0_0_4_0_1_0_0': 90,
'4_0_2_0_0_0_3_0_0_0': 90,
'6_0_4_0_0_2_6_2_0_0': 90,
'4_0_2_0_0_0_3_1_1_0': 89,
'6_0_4_0_1_3_5_0_1_0': 89,
'16_0_4_0_0_4_0_1_0_0': 88,
'7_0_3_0_0_1_0_0_0_0': 88,
'3_0_0_0_0_3_3_0_0_0': 86,
'6_0_4_0_0_3_0_1_0_0': 86,
'8_0_3_0_0_2_0_0_0_0': 86,
'4_1_0_0_0_0_4_0_1_0': 85,
'6_0_3_1_1_0_8_2_0_0': 85,
'6_0_4_0_0_4_0_0_0_0': 84,
'7_0_3_1_1_3_5_2_1_0': 84,
'2_0_0_0_0_2_0_0_0_0': 84,
'7_0_3_0_0_2_0_2_0_0': 83,
'3_0_0_0_0_2_3_1_1_0': 83,
'6_0_4_0_0_0_6_4_0_0': 83,
'6_0_3_1_1_0_0_0_0_0': 82,
'3_1_0_0_0_0_3_0_1_0': 82,
'6_0_4_0_1_2_6_2_0_0': 80,
'6_0_4_0_0_3_6_3_0_0': 80,
'4_1_2_0_0_2_4_0_1_0': 80,
'6_0_2_0_0_2_0_1_0_0': 80,
'8_0_3_0_0_2_6_3_0_0': 79,
'7_0_3_0_0_1_0_1_0_0': 79,
'6_0_3_1_1_3_6_3_4_0': 78,
'3_0_1_0_0_0_3_0_0_0': 78,
'1_1_0_0_0_0_0_0_1_0': 78,
'6_0_3_1_1_3_6_3_0_0': 77,
'2_0_0_0_0_3_2_0_0_0': 77,
'7_0_2_0_0_1_0_0_0_0': 76,
'8_0_4_0_0_2_0_0_0_0': 76,
'6_0_4_0_0_0_7_2_0_0': 76,
'3_0_0_0_0_0_2_0_0_0': 75,
'4_0_2_0_0_2_4_0_0_0': 75,
'4_1_2_0_0_0_3_1_1_0': 75,
'8_0_3_0_0_0_6_2_0_0': 75,
'1_0_0_0_0_2_1_1_0_0': 75,
'3_1_1_0_0_0_0_0_0_0': 74,
'6_0_3_0_0_2_0_0_0_0': 74,
'6_0_4_0_1_3_6_0_3_0': 74,
'6_0_3_1_1_2_5_2_4_1': 74,
'6_0_4_0_1_2_5_0_4_0': 74,
'7_0_4_0_0_1_0_0_0_0': 68,
'6_0_3_1_1_1_6_2_0_0': 73,
'6_0_4_0_0_0_6_1_0_0': 73,
'7_0_3_1_1_2_5_2_4_0': 72,
'6_0_4_0_0_2_8_2_0_0': 72,
'6_0_4_0_0_1_8_2_0_0': 71,
'4_0_0_0_0_0_3_0_0_0': 71,
'6_0_4_0_0_1_6_2_0_0': 71,
'3_0_0_0_0_0_1_0_0_0': 71,
'7_0_4_0_1_3_6_0_1_0': 70,
'9_0_4_0_0_0_8_1_0_0': 70,
'7_0_4_0_1_3_6_0_2_0': 70,
'7_0_3_1_1_2_6_2_4_0': 69,
'7_0_4_0_0_2_0_0_0_0': 69,
'6_0_4_0_0_2_0_2_0_0': 69,
'4_1_0_0_0_0_4_0_0_0': 69,
'8_0_3_0_0_1_6_3_0_0': 69,
'3_0_0_0_0_3_3_1_1_0': 69,
'6_0_4_0_1_2_6_1_1_0': 68,
'8_0_3_0_0_0_7_2_0_0': 68,
'6_0_4_0_1_0_7_3_0_0': 68,
'7_0_3_1_1_3_5_2_2_0': 67,
'2_0_0_0_0_3_0_0_0_0': 66,
'9_0_4_0_0_0_6_2_0_0': 66,
'4_0_3_0_0_0_3_1_1_0': 66,
'6_0_4_0_1_3_5_0_2_0': 66,
'3_1_0_0_0_0_0_0_0_0': 66,
'6_0_3_1_1_3_6_2_5_0': 66,
'6_0_4_0_0_0_8_1_0_0': 66,
'4_0_0_0_0_2_4_0_0_0': 65,
'6_0_4_0_0_3_6_2_0_0': 65,
'6_0_3_0_1_3_6_0_1_0': 65,
'6_0_3_0_1_3_5_0_1_0': 64,
'2_0_0_0_0_1_2_0_0_0': 64,
'1_0_0_0_1_0_1_0_0_0': 64,
'6_0_3_0_0_2_0_1_0_0': 63,
'6_0_4_0_1_2_6_0_5_0': 63,
'7_0_2_0_0_0_6_2_0_0': 63,
'6_0_3_1_1_3_5_3_4_0': 63,
'7_0_3_0_1_0_6_2_0_0': 63,
'3_0_0_0_0_1_3_0_0_0': 62,
'4_1_2_0_0_3_4_0_1_0': 62,
'6_0_3_1_1_0_7_3_0_0': 62,
'4_0_3_0_0_0_4_0_0_0': 62,
'8_0_3_0_0_3_6_3_0_0': 62,
'3_0_1_0_0_0_3_1_1_0': 61,
'6_0_4_0_1_2_3_0_3_0': 61,
'1_0_1_0_0_0_0_0_0_0': 61,
'7_0_3_0_1_3_6_1_2_0': 61,
'1_1_0_0_0_2_1_0_1_0': 61,
'8_0_3_0_0_0_8_1_0_0': 60,
'3_1_0_0_0_2_4_0_0_0': 60,
'4_0_2_0_0_0_4_0_1_0': 60,
'6_0_3_1_1_2_7_2_0_1': 60,
'4_0_2_0_0_3_4_0_0_0': 60,
'7_0_4_0_0_3_0_0_0_0': 60,
'2_0_0_0_0_1_0_0_0_0': 60,
'1_0_0_0_0_3_1_1_0_0': 60,
'6_0_4_0_1_3_6_2_0_0': 59,
'7_0_3_0_1_0_6_3_0_0': 59,
'7_0_4_0_1_3_6_0_3_0': 59,
'4_0_1_0_0_2_4_0_0_0': 59,
'3_1_0_0_0_2_3_0_0_0': 59,
'6_0_4_0_1_0_8_2_0_0': 59,
'7_0_3_1_1_3_5_3_2_0': 58,
'8_0_3_0_0_2_0_2_0_0': 58,
'6_0_3_0_1_0_8_1_0_0': 58,
'2_0_0_0_0_0_3_1_1_0': 58,
'3_1_1_0_0_0_4_0_1_0': 57,
'3_0_1_0_0_0_4_0_0_0': 57,
'6_0_4_0_1_0_0_0_0_0': 57,
'7_0_3_1_1_3_5_3_1_0': 57,
'6_0_3_1_1_3_5_2_4_0': 56,
'6_0_2_0_0_2_0_0_0_0': 56,
'6_0_4_0_1_3_5_0_3_0': 56,
'7_0_3_0_0_2_6_3_0_0': 56,
'1_0_0_1_0_0_1_0_0_0': 56,
'7_0_4_0_1_0_6_2_0_0': 56,
'6_0_4_0_0_3_8_2_0_0': 56,
'16_0_3_1_1_2_5_2_1_0': 56,
'16_0_4_0_0_4_0_0_0_0': 56,
'1_0_0_0_1_0_0_0_0_0': 55,
'7_0_3_0_0_3_0_0_0_0': 55,
'6_0_3_1_1_2_6_2_6_1': 55,
'16_0_3_1_1_2_5_2_2_0': 55,
'6_0_3_1_1_1_6_3_0_0': 55,
'1_0_0_0_0_2_2_0_0_0': 54,
'4_0_0_0_0_3_4_0_0_0': 54,
'6_0_4_0_0_2_7_3_0_0': 54,
'4_1_2_0_0_0_0_0_0_0': 54,
'7_0_3_0_0_3_0_1_0_0': 54,
'6_0_3_1_1_2_8_1_0_1': 54,
'6_0_4_0_1_2_3_0_4_0': 53,
'6_0_4_0_1_2_6_1_2_0': 53,
'35_0_4_0_0_1_0_1_0_0': 53,
'1_0_0_1_0_0_2_0_0_0': 53,
'4_1_2_0_0_0_3_0_1_0': 53,
'1_0_0_0_0_0_3_0_0_0': 53,
'7_0_3_1_1_2_6_3_0_0': 53,
'8_0_4_0_0_0_6_2_0_0': 52,
'17_0_4_0_0_0_6_2_0_0': 52,
'4_1_2_0_0_1_4_0_1_0': 52,
'6_0_4_0_1_2_4_0_3_0': 51,
'6_0_4_0_0_1_7_3_0_0': 51,
'7_0_3_0_1_3_6_0_2_0': 51,
'3_0_0_0_0_2_0_0_0_0': 51,
'6_0_4_0_1_3_6_1_1_0': 51,
'2_0_0_0_0_2_1_0_0_0': 50,
'6_0_4_0_1_0_7_2_0_0': 50,
'7_0_3_0_1_3_6_0_1_0': 50,
'9_0_4_0_0_0_6_3_0_0': 49,
'6_0_4_0_1_2_8_0_1_0': 49,
'8_0_3_1_1_2_5_2_1_0': 49,
'1_0_0_0_0_2_0_0_1_0': 49,
'3_0_0_0_0_0_4_0_1_0': 49,
'3_1_0_0_0_3_3_0_0_0': 49,
'6_0_4_0_1_4_6_0_1_0': 49,
'7_0_3_0_1_3_6_1_1_0': 49,
'7_0_3_1_1_0_7_2_0_0': 48,
'1_0_0_0_0_4_1_0_0_0': 48,
'1_0_0_0_0_3_2_0_0_0': 48,
'3_1_0_0_0_3_4_0_0_0': 48,
'1_0_0_1_0_2_0_0_0_0': 48,
'3_0_0_0_0_0_3_0_1_0': 48,
'7_0_3_1_1_3_6_2_1_0': 47,
'4_0_0_0_0_2_3_1_1_0': 47,
'6_0_3_0_0_0_6_2_0_0': 47,
'8_0_3_0_0_0_7_3_0_0': 47,
'16_0_4_0_0_2_0_1_0_0': 46,
'3_0_0_0_0_2_4_0_0_0': 46,
'6_0_3_1_1_0_6_4_0_0': 46,
'6_0_4_0_1_2_6_3_0_0': 46,
'4_1_1_0_0_2_4_0_1_0': 46,
'8_0_3_1_1_2_5_2_2_0': 46,
'4_0_1_0_0_3_4_0_0_0': 46,
'4_0_2_0_0_2_3_0_0_0': 45,
'7_0_3_0_1_3_5_0_1_0': 45,
'3_1_1_0_0_0_3_0_1_0': 45,
'6_0_4_0_1_2_7_0_3_0': 45,
'6_0_3_1_1_3_7_2_0_0': 45,
'6_0_3_0_0_2_8_1_0_0': 45,
'3_0_1_1_0_0_3_1_1_0': 45,
'6_0_4_0_1_3_8_0_1_0': 45,
'1_1_0_0_0_2_0_0_0_0': 45,
'4_0_1_0_0_0_3_0_0_0': 45,
'16_0_3_1_1_2_5_2_3_0': 45,
'6_0_4_0_1_3_6_0_4_0': 45,
'7_0_3_1_1_3_5_2_3_0': 45,
'6_0_4_0_1_0_8_1_0_0': 45,
'1_1_0_0_0_0_1_1_1_0': 45,
'17_0_4_0_0_0_0_0_0_0': 44,
'8_0_4_0_1_2_6_0_3_0': 44,
'1_1_0_0_0_3_1_0_1_0': 44,
'2_0_0_0_0_3_1_0_0_0': 44,
'6_0_4_0_1_2_7_0_1_0': 44,
'4_0_2_0_0_1_4_0_0_0': 43,
'3_0_0_0_0_1_3_1_1_0': 43,
'17_0_4_0_0_0_6_3_0_0': 43,
'3_1_0_0_0_1_3_0_0_0': 43,
'6_0_3_0_1_3_5_1_1_0': 43,
'6_0_3_0_1_3_8_0_1_0': 43,
'7_0_3_1_1_0_0_0_0_0': 43,
'8_0_4_0_0_0_6_3_0_0': 43,
'6_0_4_0_1_4_5_0_1_0': 42,
'8_-1_3_0_0_1_0_0_0_0': 42,
'7_0_3_0_0_0_6_2_0_0': 42,
'7_0_3_1_1_2_6_2_0_0': 42,
'6_0_4_0_1_3_6_1_2_0': 42,
'6_0_3_1_1_0_6_1_0_0': 42,
'7_0_3_0_1_3_6_1_3_0': 42,
'6_0_3_0_1_3_5_0_2_0': 41,
'1_0_0_1_0_3_0_0_0_0': 41,
'4_1_1_0_0_0_4_0_0_0': 41,
'6_0_4_0_1_2_5_0_5_0': 41,
'3_1_0_0_0_1_4_0_0_0': 41,
'3_1_0_0_0_2_4_0_1_0': 41,
'6_0_4_0_1_2_3_0_2_0': 40,
'4_0_0_0_0_0_4_0_1_0': 40,
'4_0_2_0_0_2_3_1_1_0': 40,
'6_0_4_0_0_3_7_3_0_0': 40,
'7_0_3_0_0_3_6_3_0_0': 40,
'7_0_3_0_1_3_6_0_3_0': 40,
'6_0_4_0_1_3_5_1_1_0': 40,
'3_0_1_0_0_2_3_0_0_0': 40,
'2_0_1_0_0_0_0_0_0_0': 40,
'3_1_0_0_0_2_3_0_1_0': 40,
'8_0_3_0_0_0_8_4_0_0': 40,
'4_1_0_0_0_2_4_0_1_0': 39,
'1_1_0_0_0_3_0_0_0_0': 39,
'1_1_0_0_0_2_0_0_1_0': 39,
'3_0_0_0_0_3_4_0_0_0': 39,
'1_1_1_0_0_0_0_0_1_0': 39,
'8_0_3_1_1_2_5_2_3_0': 39,
'7_0_3_0_0_1_6_3_0_0': 39,
'7_0_3_0_1_3_5_0_2_0': 39,
'6_0_4_0_1_3_5_0_4_0': 39,
'1_0_0_0_0_1_1_1_0_0': 39,
'7_1_3_0_0_3_0_1_0_0': 39,
'6_0_3_1_1_3_6_2_6_0': 39,
'4_0_2_0_0_3_3_1_1_0': 39,
'3_0_0_0_0_2_2_0_0_0': 39,
'1_0_0_0_1_0_2_0_0_0': 39,
'6_0_4_0_1_3_3_0_3_0': 38,
'6_0_4_0_1_2_7_0_2_0': 38,
'6_0_4_0_1_2_4_0_2_0': 38,
'6_0_3_1_1_3_8_1_0_0': 38,
'6_0_3_0_1_3_6_0_2_0': 38,
'7_0_3_0_1_3_5_1_2_0': 38,
'6_0_4_0_1_3_6_1_3_0': 38,
'3_0_0_0_0_3_0_0_0_0': 38,
'6_0_4_0_1_0_6_4_0_0': 38,
'7_0_4_0_1_3_6_0_4_0': 38,
'6_0_4_0_1_1_6_2_0_0': 38,
'6_0_4_0_0_2_6_4_0_0': 38,
'7_0_4_0_0_0_6_2_0_0': 38,
'1_0_0_0_0_3_0_0_1_0': 38,
'6_0_4_0_0_0_8_4_0_0': 38,
'6_0_4_0_1_4_6_0_2_0': 38,
'4_0_3_0_0_0_4_0_1_0': 38,
'6_0_4_0_1_2_3_0_1_0': 37,
'1_0_1_0_0_0_2_0_0_0': 37,
'4_1_1_0_0_1_4_0_1_0': 37,
'4_1_1_0_1_0_4_0_0_0': 37,
'6_0_4_0_0_1_6_4_0_0': 37,
'4_0_1_1_1_0_4_0_1_0': 37,
'16_0_4_0_0_0_8_1_0_0': 37,
'6_0_3_0_0_3_8_1_0_0': 37,
'7_0_3_0_1_2_5_0_1_0': 37,
'6_0_3_1_1_2_8_2_0_1': 37,
'4_0_0_0_0_3_3_1_1_0': 37,
'7_0_3_1_1_0_7_3_0_0': 37,
'7_0_3_0_1_2_8_0_1_0': 36,
'4_1_1_0_0_0_3_0_0_0': 36,
'6_0_3_0_1_3_5_0_3_0': 36,
'4_0_0_0_0_1_4_0_0_0': 36,
'7_0_3_1_1_3_6_3_0_0': 36,
'4_0_0_0_0_2_3_0_0_0': 36,
'4_0_2_0_0_3_3_0_0_0': 36,
'3_0_0_0_0_2_1_0_0_0': 36,
'6_0_4_0_1_3_3_0_1_0': 36,
'7_0_3_1_1_3_5_3_3_0': 35,
'6_0_3_1_1_2_0_0_0_1': 35,
'6_0_4_0_1_0_6_1_0_0': 35,
'7_0_4_0_0_0_6_3_0_0': 35,
'8_0_3_0_0_0_6_1_0_0': 35,
'8_0_3_0_0_0_0_0_0_0': 35,
'6_0_4_0_1_2_5_1_1_0': 35,
'2_0_0_0_0_1_1_0_0_0': 35,
'1_0_1_0_0_2_0_0_0_0': 35,
'4_1_1_0_0_3_4_0_1_0': 35,
'6_0_3_0_0_3_0_2_0_0': 35,
'8_0_3_0_0_2_6_2_0_0': 35,
'7_0_4_0_0_0_8_4_0_0': 35,
'7_0_3_0_1_3_5_1_1_0': 34,
'6_0_4_0_1_2_6_1_3_0': 34,
'6_0_3_0_0_0_6_3_0_0': 34,
'4_0_2_0_0_2_4_0_1_0': 34,
'6_0_4_0_1_3_3_0_2_0': 34,
'3_1_1_0_0_0_3_0_0_0': 34,
'1_0_0_0_0_1_2_0_0_0': 34,
'4_1_0_0_0_2_4_0_0_0': 33,
'3_1_1_0_0_2_0_0_0_0': 33,
'4_0_0_0_0_0_0_0_0_0': 33,
'4_1_0_0_0_3_4_0_1_0': 33,
'4_0_3_0_0_0_0_0_0_0': 33,
'6_0_4_0_0_2_6_1_0_0': 33,
'7_0_3_1_1_2_5_2_5_0': 33,
'6_0_3_0_1_3_6_1_1_0': 33,
'4_0_1_0_1_0_4_0_0_0': 33,
'6_0_4_0_1_3_6_3_0_0': 33,
'8_0_4_0_1_2_6_0_1_0': 33,
'8_0_4_0_1_2_6_0_2_0': 33,
'6_0_4_0_0_3_6_4_0_0': 33,
'6_0_3_1_1_3_6_3_5_0': 32,
'7_0_4_0_1_3_5_0_1_0': 32,
'6_0_3_0_1_3_5_1_2_0': 32,
'6_0_4_0_1_2_7_3_0_0': 32,
'3_1_0_0_0_3_3_0_1_0': 32,
'3_1_0_0_0_3_4_0_1_0': 32,
'1_1_0_0_0_3_0_0_1_0': 32,
'7_0_3_0_1_2_6_2_0_0': 32,
'7_0_3_0_1_2_6_0_1_0': 32,
'1_0_0_1_0_1_0_0_0_0': 32,
'1_1_0_0_0_0_2_0_0_0': 32,
'6_0_4_0_0_3_0_2_0_0': 32,
'7_0_3_1_1_3_6_2_2_0': 32,
'6_0_3_1_1_0_7_1_0_0': 32,
'6_0_3_1_1_1_7_2_0_0': 32,
'7_0_4_0_1_3_5_0_2_0': 31,
'2_0_0_0_0_0_4_0_0_0': 31,
'3_1_0_0_0_4_3_1_1_0': 31,
'3_1_0_0_0_2_0_0_0_0': 31,
'3_0_2_0_0_0_3_1_1_0': 31,
'4_0_3_0_0_0_3_0_0_0': 31,
'6_0_4_0_1_2_7_0_4_0': 31,
'6_0_2_0_0_0_6_2_0_0': 31,
'4_1_1_0_0_0_3_1_1_0': 31,
'7_0_2_0_0_1_6_2_0_0': 31,
'3_0_0_0_0_3_2_0_0_0': 31,
'6_0_3_0_1_3_6_0_3_0': 31,
'6_0_4_0_1_2_5_1_2_0': 31,
'7_0_3_1_1_2_6_2_5_0': 31,
'4_1_2_0_0_2_3_1_1_0': 31,
'7_0_3_1_1_3_6_2_0_0': 31,
'6_0_4_0_0_0_0_0_0_0': 31,
'1_0_0_0_1_2_1_0_0_0': 31,
'4_0_0_0_0_1_3_1_1_0': 31,
'8_0_3_0_0_2_7_2_0_0': 31,
'3_0_0_0_0_1_0_0_0_0': 31,
'3_0_1_0_0_3_3_0_0_0': 31,
'4_0_1_1_1_0_3_1_1_0': 31,
'8_0_4_0_1_0_6_2_0_0': 31,
'6_0_4_0_0_2_7_2_0_0': 31,
'8_0_4_0_1_2_6_0_4_0': 30,
'4_0_2_0_1_0_4_0_0_0': 30,
'1_0_0_0_0_4_0_0_0_0': 30,
'4_0_3_0_0_2_3_1_1_0': 30,
'8_0_3_0_1_2_6_1_1_0': 30,
'6_0_4_0_1_3_5_1_2_0': 30,
'7_0_3_0_1_3_5_0_3_0': 30,
'9_0_4_0_0_2_8_1_0_0': 30,
'3_0_1_0_0_2_3_1_1_0': 30,
'4_0_2_0_0_1_3_1_1_0': 30,
'7_0_3_0_1_3_6_1_4_0': 30,
'3_1_1_0_0_2_4_0_1_0': 30,
'1_0_0_1_0_2_2_0_0_0': 30,
'8_0_3_0_0_2_8_1_0_0': 30,
'6_0_3_1_1_2_7_3_0_1': 30,
'6_0_3_1_1_3_8_2_0_0': 30,
'1_1_0_0_0_1_1_0_1_0': 30,
'8_0_3_1_1_0_6_3_0_0': 30,
'7_0_3_0_0_0_7_2_0_0': 29,
'6_0_4_0_0_3_8_1_0_0': 29,
'6_0_3_0_0_1_0_0_0_0': 29,
'6_0_4_0_1_4_5_1_1_0': 29,
'6_0_4_0_1_2_4_0_1_0': 29,
'6_0_4_0_0_1_7_2_0_0': 29,
'8_0_3_0_0_3_6_2_0_0': 29,
'6_0_3_0_0_0_7_1_0_0': 29,
'16_0_4_0_0_4_0_2_0_0': 29,
'6_0_4_0_1_2_7_1_1_0': 29,
'7_0_4_0_1_2_6_0_3_0': 29,
'16_0_3_1_1_2_5_2_4_0': 29,
'7_0_3_0_1_2_6_3_0_0': 29,
'2_0_0_0_0_0_1_0_1_0': 29,
'6_0_3_0_1_0_6_3_0_0': 29,
'3_1_0_0_0_1_3_0_1_0': 29,
'7_0_3_1_1_3_5_3_4_0': 28,
'6_0_3_1_1_2_6_2_7_1': 28,
'1_1_1_1_0_0_1_0_1_0': 28,
'4_0_1_0_0_1_4_0_0_0': 28,
'3_1_1_0_0_4_3_1_1_0': 28,
'6_0_3_1_1_0_8_4_0_0': 28,
'6_0_3_1_1_3_0_0_0_0': 28,
'1_1_0_0_0_1_0_0_0_0': 28,
'4_0_0_0_0_3_3_0_0_0': 28,
'3_1_1_0_0_3_0_0_0_0': 28,
'2_1_0_0_0_0_1_1_1_0': 28,
'6_0_4_0_1_2_4_0_4_0': 28,
'16_0_4_0_0_2_0_0_0_0': 28,
'2_0_0_0_0_0_3_0_0_0': 28,
'2_0_0_0_0_0_4_0_1_0': 28,
'7_0_2_0_0_2_6_2_0_0': 28,
'6_0_4_0_1_2_0_0_0_0': 28,
'6_0_4_0_0_2_8_1_0_0': 28,
'7_0_3_0_0_0_8_1_0_0': 28,
'3_0_2_0_0_0_3_0_0_0': 28,
'1_1_0_0_0_0_1_0_0_0': 28,
'8_0_3_1_1_2_5_2_4_0': 27,
'6_0_4_0_1_3_4_0_1_0': 27,
'8_0_4_0_1_2_5_0_1_0': 27,
'2_0_1_0_0_0_1_0_0_0': 27,
'9_0_4_0_0_2_6_2_0_0': 27,
'4_0_1_0_0_0_3_1_1_0': 27,
'3_0_0_0_0_1_4_0_0_0': 27,
'6_0_3_1_1_2_5_2_5_1': 27,
'6_0_3_0_1_2_6_0_1_0': 27,
'6_0_4_0_1_3_3_0_4_0': 27,
'8_0_3_0_1_2_5_1_1_0': 27,
'7_0_3_0_1_2_5_0_2_0': 27,
'7_0_3_1_1_3_5_2_4_0': 27,
'8_0_3_0_0_0_8_2_0_0': 27,
'3_0_1_0_0_0_4_0_1_0': 27,
'1_0_0_0_1_2_0_0_0_0': 27,
'4_0_0_0_1_0_4_0_0_0': 27,
'4_1_0_0_0_0_3_1_1_0': 27,
'6_0_2_0_0_0_7_1_0_0': 27,
'3_1_0_0_0_1_4_0_1_0': 27,
'4_0_3_0_0_2_4_0_0_0': 27,
'4_0_1_1_1_0_4_0_0_0': 27,
'7_0_3_1_1_1_6_3_0_0': 27,
'3_0_1_0_0_2_4_0_0_0': 27,
'7_0_3_0_1_3_6_0_4_0': 27,
'6_0_3_1_1_3_5_3_5_0': 27,
'16_0_3_0_0_1_0_0_0_0': 27,
'4_0_2_0_0_1_3_0_0_0': 27,
'8_0_3_0_0_3_8_1_0_0': 27,
'2_0_0_1_0_0_0_0_0_0': 27,
'7_0_4_0_1_2_6_2_0_0': 27,
'6_0_3_0_1_0_6_2_0_0': 27,
'1_1_1_0_0_0_0_0_0_0': 27,
'6_0_4_0_1_4_6_1_1_0': 26,
'6_0_4_0_1_3_5_1_3_0': 26,
'6_0_4_0_0_3_7_2_0_0': 26,
'6_0_4_0_0_0_7_1_0_0': 26,
'2_0_0_0_0_2_3_1_1_0': 26,
'3_0_0_0_0_3_1_0_0_0': 26,
'6_0_4_0_1_4_6_1_3_0': 26,
'7_0_4_0_1_3_5_0_3_0': 26,
'16_0_3_1_1_0_6_3_0_0': 26,
'6_0_3_1_1_1_8_1_0_0': 26,
'7_0_3_1_1_0_6_1_0_0': 26,
'1_0_0_1_0_2_1_0_0_0': 26,
'3_0_1_0_0_1_3_0_0_0': 26,
'4_1_0_0_0_1_4_0_1_0': 26,
'6_0_3_0_1_3_6_1_2_0': 26,
'6_0_4_0_1_3_6_0_5_0': 26,
'4_1_1_0_0_0_3_0_1_0': 26,
'6_0_4_0_1_4_6_0_3_0': 25,
'6_0_4_0_1_2_5_1_3_0': 25,
'6_0_4_0_1_3_7_0_1_0': 25,
'6_0_4_0_1_2_3_0_5_0': 25,
'53_0_4_0_0_1_0_1_0_0': 25,
'8_0_3_0_1_2_5_0_1_0': 25,
'4_0_2_0_0_3_4_0_1_0': 25,
'4_1_1_0_0_2_4_0_0_0': 25,
'3_0_0_0_0_1_2_0_0_0': 25,
'6_0_3_0_1_2_8_1_0_0': 25,
'3_0_1_0_0_3_3_1_1_0': 25,
'1_0_0_1_0_0_1_1_0_0': 25,
'3_0_1_0_0_1_3_1_1_0': 25,
'7_0_4_0_1_0_6_3_0_0': 25,
'1_0_0_1_0_3_1_0_0_0': 25,
'7_0_3_0_1_3_5_1_3_0': 24,
'6_0_4_0_1_4_5_1_2_0': 24,
'6_0_4_0_1_3_4_0_3_0': 24,
'7_0_4_0_1_2_6_0_2_0': 24,
'1_0_1_1_0_0_1_0_0_0': 24,
'6_0_3_0_0_2_6_2_0_0': 24,
'17_0_4_0_0_2_6_2_0_0': 24,
'4_1_0_0_0_0_3_0_0_0': 24,
'6_0_3_0_0_1_8_1_0_0': 24
}



def set_seed(seed):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def get_training_config(config_path, model_name, dataset):
    with open(config_path, "r") as conf:
        full_config = yaml.load(conf, Loader=yaml.FullLoader)
    dataset_specific_config = full_config["global"]
    model_specific_config = full_config[dataset][model_name]

    if model_specific_config is not None:
        specific_config = dict(dataset_specific_config, **model_specific_config)
    else:
        specific_config = dataset_specific_config

    specific_config["model_name"] = model_name
    return specific_config


def check_writable(path, overwrite=True):
    if not os.path.exists(path):
        os.makedirs(path)
    elif overwrite:
        shutil.rmtree(path)
        os.makedirs(path)
    else:
        pass


def check_readable(path):
    if not os.path.exists(path):
        raise ValueError(f"No such file or directory! {path}")


def timetz(*args):
    tz = pytz.timezone("US/Pacific")
    return datetime.now(tz).timetuple()


def get_logger(filename, console_log=False, log_level=logging.INFO):
    tz = pytz.timezone("US/Pacific")
    log_time = datetime.now(tz).strftime("%b%d_%H_%M_%S")
    logger = logging.getLogger(__name__)
    logger.propagate = False  # avoid duplicate logging
    logger.setLevel(log_level)

    # Clean logger first to avoid duplicated handlers
    for hdlr in logger.handlers[:]:
        logger.removeHandler(hdlr)

    file_handler = logging.FileHandler(filename)
    formatter = logging.Formatter("%(asctime)s: %(message)s", datefmt="%b%d %H-%M-%S")
    formatter.converter = timetz
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    if console_log:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    return logger


def idx_split(idx, ratio, seed=0, train_or_infer=None):
    """
    randomly split idx into two portions with ratio% elements and (1 - ratio)% elements
    """
    set_seed(seed)
    n = len(idx)   # idx starts from 40
    cut = int(n * ratio)  # n 8000, cut 1600, ratio 0.2
    # print(f"n {n}, cut {cut}, ratio {ratio}") # n 8000, cut 1600, ratio 0.2
    if train_or_infer == "train":
        idx_idx_shuffle = torch.randperm(n)
        idx1_idx, idx2_idx = idx_idx_shuffle[:cut], idx_idx_shuffle[cut:]
    elif train_or_infer == "infer":
        idx_idx_list = list(range(n))
        idx1_idx, idx2_idx = idx_idx_list[:cut], idx_idx_list[cut:]
    idx1, idx2 = idx[idx1_idx], idx[idx2_idx]
    # assert((torch.cat([idx1, idx2]).sort()[0] == idx.sort()[0]).all())
    return idx1, idx2  # idx1 is test_ind


def graph_split(idx_train, idx_val, idx_test, rate, seed, train_or_infer):
    """
    Args:
        The original setting was transductive. Full graph is observed, and idx_train takes up a small portion.
        Split the graph by further divide idx_test into [idx_test_tran, idx_test_ind].
        rate = idx_test_ind : idx_test (how much test to hide for the inductive evaluation)

        Ex. Ogbn-products
        loaded     : train : val : test = 8 : 2 : 90, rate = 0.2
        after split: train : val : test_tran : test_ind = 8 : 2 : 72 : 18

    Return:
        Indices start with 'obs_' correspond to the node indices within the observed subgraph,
        where as indices start directly with 'idx_' correspond to the node indices in the original graph
    """
    idx_test_ind, idx_test_tran = idx_split(idx_test, rate, seed, train_or_infer)

    idx_obs = torch.cat([idx_train, idx_val])
    N1, N2 = idx_train.shape[0], idx_val.shape[0]
    obs_idx_all = torch.arange(idx_obs.shape[0])
    obs_idx_train = obs_idx_all[:N1]
    obs_idx_val = obs_idx_all[N1 : N1 + N2]
    obs_idx_test = idx_test

    # print(f"obs_idx_train {obs_idx_train}")
    # print(f"obs_idx_train {obs_idx_train.shape}")
    # print(f"obs_idx_val {obs_idx_val}")
    # print(f"obs_idx_val {obs_idx_val.shape}")
    # print(f"obs_idx_test {obs_idx_test}")
    # print(f"obs_idx_test {obs_idx_test.shape}")
    # print(f"idx_test_ind {idx_test_ind}")
    # print(f"idx_test_ind {idx_test_ind.shape}")
    idx_test_ind = torch.tensor(list(range(N1 + N2 + N2, N1 + N2 + N2 + N2 + 1)))
    return obs_idx_train, obs_idx_val, obs_idx_test, obs_idx_all, idx_test_ind


def get_evaluator(dataset):
    if dataset in CPF_data + NonHom_data + BGNN_data:

        def evaluator(out, labels):
            pred = out.argmax(1)
            return pred.eq(labels).float().mean().item()

    elif dataset in OGB_data:
        ogb_evaluator = Evaluator(dataset)

        def evaluator(out, labels):
            pred = out.argmax(1, keepdim=True)
            input_dict = {"y_true": labels.unsqueeze(1), "y_pred": pred}
            return ogb_evaluator.eval(input_dict)["acc"]

    else:
        raise ValueError("Unknown dataset")

    return evaluator


def get_evaluator(dataset):
    def evaluator(out, labels):
        pred = out.argmax(1)
        return pred.eq(labels).float().mean().item()

    return evaluator


def compute_min_cut_loss(g, out):
    out = out.to("cpu")
    g = g.to("cpu")
    S = out.exp()
    A = g.adj().to_dense()
    D = g.in_degrees().float().diag()
    print(S.device, A.device, D.device)
    min_cut = (
        torch.matmul(torch.matmul(S.transpose(1, 0), A), S).trace()
        / torch.matmul(torch.matmul(S.transpose(1, 0), D), S).trace()
    )
    return min_cut.item()


def feature_prop(feats, g, k):
    """
    Augment node feature by propagating the node features within k-hop neighborhood.
    The propagation is done in the SGC fashion, i.e. hop by hop and symmetrically normalized by node degrees.
    """
    assert feats.shape[0] == g.num_nodes()

    degs = g.in_degrees().float().clamp(min=1)
    norm = torch.pow(degs, -0.5).unsqueeze(1)

    # compute (D^-1/2 A D^-1/2)^k X
    for _ in range(k):
        feats = feats * norm
        g.ndata["h"] = feats
        g.update_all(fn.copy_u("h", "m"), fn.sum("m", "h"))
        feats = g.ndata.pop("h")
        feats = feats * norm

    return feats
